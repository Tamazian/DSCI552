{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# DSCI552: HW1\n",
    "### Alain Tamazian\n",
    "### ID#: 2073746513"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "-------------\n",
    "### Important Notice:\n",
    "\n",
    "Side note 1:\n",
    "I figured out that using the \".dat\" instead of \".arff\" can output slightly different results since \".dat\" uses rounded values. Such as difference is very noticable in d.ii. It also leads to a small discepency in d.i.A, and possibly in other questions too. Please keep that in mind when grading.\n",
    "\n",
    "Side note 2:\n",
    "I was told by TAs that 1 is not a valid k* since it uses itself as the nearest neighbors. Accordingly, I tweaked my program to never get k* = 1. Otherwise, k* = 1 for d.i.A and d.ii, which would by extension affect the output of d.i.B. Please keep that in mind."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "------------------\n",
    "## Part (a) and (b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell for all imports necessary for HW1\n",
    "\n",
    "from scipy.io.arff import loadarff \n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.neighbors import KNeighborsClassifier as knn\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from warnings import simplefilter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "file = \"../data/vertebral_column_data/column_2C_weka.arff\"\n",
    "\n",
    "med_data = loadarff(file)\n",
    "med_df = pd.DataFrame(med_data[0])\n",
    "\n",
    "pd.set_option('display.max_rows', 10)\n",
    "# uncomment the line below if you want all rows of data displayed instead of just a sample of 10\n",
    "# pd.set_option('display.max_rows', None)\n",
    "\n",
    "# display(med_df)\n",
    "\n",
    "# Could alternatively use the .dat file, by uncommenting the 3 lines below\n",
    "# file = \"../data/vertebral_column_data/column_2C.dat\"\n",
    "# col_names = [\"pelvic_incidence\", \"pelvic_tilt\", \"lumbar_lordosis_angle\", \n",
    "#          \"sacral_slope\", \"pelvic_radius\", \"grade_of_spondylolisthesis\", \"class\"]\n",
    "# med_df = pd.read_csv(file, header = None, sep = \"\\s+\", names = col_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We need to convert labels to 0 and 1 first\n",
    "# I am doing so by converting the dataframe to a dictionary \n",
    "\n",
    "med_dict = {}\n",
    "\n",
    "for col in med_df.head():\n",
    "    med_dict[col] = []\n",
    "\n",
    "for index, row in med_df.iterrows():\n",
    "    for col in med_dict.keys():\n",
    "        med_dict[col].append(row[col])\n",
    "    \n",
    "# print(med_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>pelvic_incidence</th>\n",
       "      <th>pelvic_tilt</th>\n",
       "      <th>lumbar_lordosis_angle</th>\n",
       "      <th>sacral_slope</th>\n",
       "      <th>pelvic_radius</th>\n",
       "      <th>degree_spondylolisthesis</th>\n",
       "      <th>class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>63.027817</td>\n",
       "      <td>22.552586</td>\n",
       "      <td>39.609117</td>\n",
       "      <td>40.475232</td>\n",
       "      <td>98.672917</td>\n",
       "      <td>-0.254400</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>39.056951</td>\n",
       "      <td>10.060991</td>\n",
       "      <td>25.015378</td>\n",
       "      <td>28.995960</td>\n",
       "      <td>114.405425</td>\n",
       "      <td>4.564259</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>68.832021</td>\n",
       "      <td>22.218482</td>\n",
       "      <td>50.092194</td>\n",
       "      <td>46.613539</td>\n",
       "      <td>105.985135</td>\n",
       "      <td>-3.530317</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>69.297008</td>\n",
       "      <td>24.652878</td>\n",
       "      <td>44.311238</td>\n",
       "      <td>44.644130</td>\n",
       "      <td>101.868495</td>\n",
       "      <td>11.211523</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>49.712859</td>\n",
       "      <td>9.652075</td>\n",
       "      <td>28.317406</td>\n",
       "      <td>40.060784</td>\n",
       "      <td>108.168725</td>\n",
       "      <td>7.918501</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>305</th>\n",
       "      <td>47.903565</td>\n",
       "      <td>13.616688</td>\n",
       "      <td>36.000000</td>\n",
       "      <td>34.286877</td>\n",
       "      <td>117.449062</td>\n",
       "      <td>-4.245395</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>306</th>\n",
       "      <td>53.936748</td>\n",
       "      <td>20.721496</td>\n",
       "      <td>29.220534</td>\n",
       "      <td>33.215251</td>\n",
       "      <td>114.365845</td>\n",
       "      <td>-0.421010</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>307</th>\n",
       "      <td>61.446597</td>\n",
       "      <td>22.694968</td>\n",
       "      <td>46.170347</td>\n",
       "      <td>38.751628</td>\n",
       "      <td>125.670725</td>\n",
       "      <td>-2.707880</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>308</th>\n",
       "      <td>45.252792</td>\n",
       "      <td>8.693157</td>\n",
       "      <td>41.583126</td>\n",
       "      <td>36.559635</td>\n",
       "      <td>118.545842</td>\n",
       "      <td>0.214750</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>309</th>\n",
       "      <td>33.841641</td>\n",
       "      <td>5.073991</td>\n",
       "      <td>36.641233</td>\n",
       "      <td>28.767649</td>\n",
       "      <td>123.945244</td>\n",
       "      <td>-0.199249</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>310 rows × 7 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     pelvic_incidence  pelvic_tilt  lumbar_lordosis_angle  sacral_slope  \\\n",
       "0           63.027817    22.552586              39.609117     40.475232   \n",
       "1           39.056951    10.060991              25.015378     28.995960   \n",
       "2           68.832021    22.218482              50.092194     46.613539   \n",
       "3           69.297008    24.652878              44.311238     44.644130   \n",
       "4           49.712859     9.652075              28.317406     40.060784   \n",
       "..                ...          ...                    ...           ...   \n",
       "305         47.903565    13.616688              36.000000     34.286877   \n",
       "306         53.936748    20.721496              29.220534     33.215251   \n",
       "307         61.446597    22.694968              46.170347     38.751628   \n",
       "308         45.252792     8.693157              41.583126     36.559635   \n",
       "309         33.841641     5.073991              36.641233     28.767649   \n",
       "\n",
       "     pelvic_radius  degree_spondylolisthesis  class  \n",
       "0        98.672917                 -0.254400      1  \n",
       "1       114.405425                  4.564259      1  \n",
       "2       105.985135                 -3.530317      1  \n",
       "3       101.868495                 11.211523      1  \n",
       "4       108.168725                  7.918501      1  \n",
       "..             ...                       ...    ...  \n",
       "305     117.449062                 -4.245395      0  \n",
       "306     114.365845                 -0.421010      0  \n",
       "307     125.670725                 -2.707880      0  \n",
       "308     118.545842                  0.214750      0  \n",
       "309     123.945244                 -0.199249      0  \n",
       "\n",
       "[310 rows x 7 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "labels = []\n",
    "\n",
    "for label in med_dict[\"class\"]:\n",
    "    label = str(label)\n",
    "    # I added the \"or\" operator in case you do run the program with the .dat file instead\n",
    "    if label == \"b'Abnormal'\" or label == \"AB\":\n",
    "        labels.append(1)\n",
    "    else:\n",
    "        labels.append(0)\n",
    "\n",
    "# resets and paris the existing \"class\" key with the new binary label values we converted to\n",
    "med_dict[\"class\"] = labels\n",
    "# print(med_dict)\n",
    "\n",
    "# This is our new dataframe with the classes encoded with 1 and 0\n",
    "med_df = pd.DataFrame(med_dict)\n",
    "display(med_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "-----------\n",
    "## (b).i. \n",
    "Pre-Processing and Exploratory data analysis:\n",
    "\n",
    "i. Make scatterplots of the independent variables in the dataset. Use color to show Classes 0 and 1."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# using the seaborn.pairplot() function to make the scatterplots\n",
    "# https://seaborn.pydata.org/generated/seaborn.pairplot.html\n",
    "\n",
    "pairplot = sns.pairplot(med_df, hue = \"class\")\n",
    "\n",
    "# Blue dots are obervations with a 0 (normal), and orange for 1 (abnormal)\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "----------------------\n",
    "## (b).ii.\n",
    "Pre-Processing and Exploratory data analysis:\n",
    "\n",
    "ii. Make boxplots for each of the independent variables. Use color to show Classes 0 and 1 (see ISLR p. 129)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# using the seaborn.boxplot() function\n",
    "# https://seaborn.pydata.org/generated/seaborn.boxplot.html\n",
    "\n",
    "# doing this to loop through all the independent variables \n",
    "# The last column is the dependent \"class\" variable so we exclude it\n",
    "for col in list(med_dict.keys())[:-1]:\n",
    "    boxplot = sns.boxplot(x=\"class\", y=col, hue=\"class\", data=med_df)\n",
    "    plt.show()\n",
    "    print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "----------------------\n",
    "## (b).iii.\n",
    "Pre-Processing and Exploratory data analysis:\n",
    "\n",
    "iii. Select the first 70 rows of Class 0 and the first 140 rows of Class 1 as the training set and the rest of the data as the test set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# divide the entire dataset into seperate training and testing sets\n",
    "\n",
    "# Seperate the rows with class 0 from 1\n",
    "class0_df = med_df[(med_df[\"class\"] == 0)]\n",
    "class1_df = med_df[(med_df[\"class\"] == 1)]\n",
    "\n",
    "# Create the training set dataframe with the first 70 rows of Class 0 and the first 140 rows of Class 1\n",
    "train_set = [class0_df[:70], class1_df[:140]]\n",
    "# ignore_index argument basically, resets the index for the new df\n",
    "train_set_df = pd.concat(train_set, ignore_index=True)\n",
    "print(\"Training Set\")\n",
    "display(train_set_df)\n",
    "\n",
    "# Create the testing set dataframe with the remaining observations \n",
    "test_set = [class0_df[70:], class1_df[140:]]\n",
    "test_set_df = pd.concat(test_set, ignore_index=True)\n",
    "print(\"\\nTesting Set\")\n",
    "display(test_set_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "----------------------\n",
    "## (c).i.\n",
    "Classification using KNN on Vertebral Column Data Set\n",
    "\n",
    "i. Write code for k-nearest neighbors with Euclidean metric (or use a software package)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Will be using the scikit-learn package/libary\n",
    "# specifically, the sklearn.neighborsKNeighborsClassifier algorithm\n",
    "\n",
    "# https://scikit-learn.org/stable/modules/generated/sklearn.neighbors.KNeighborsClassifier.html#sklearn.neighbors.KNeighborsClassifier\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "----------------------\n",
    "## (c).ii.\n",
    "Classification using KNN on Vertebral Column Data Set\n",
    "\n",
    "ii. Test all the data in the test database with k nearest neighbors. Take decisions by majority polling. Plot train and test errors in terms of k for k ∈ {208, 205, . . . , 7, 4, 1, } (in reverse order). You are welcome to use smaller increments of k. Which k∗ is the most suitable k among those values? Calculate the confusion matrix, true positive rate, true negative rate, precision, and F1-score when k = k*."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "k_vals = list(range(208, 0, -3))\n",
    "\n",
    "# Split training set dateframe into two dataframes -- one for the features (x) and one for the labels (y)\n",
    "col_names = list(med_dict.keys())[:-1]\n",
    "train_attr_df = train_set_df[col_names]\n",
    "train_class_df = train_set_df[\"class\"]\n",
    "# Split testing set dateframe into two dataframes -- one for the features (x) and one for the labels (y)\n",
    "test_attr_df = test_set_df[col_names]\n",
    "test_class_df = test_set_df[\"class\"]\n",
    "\n",
    "# Initializing empty lists to gather the error rates associated with each k we test \n",
    "training_error_ratesL = []\n",
    "testing_error_ratesL = []\n",
    "\n",
    "sets = [(train_attr_df, train_class_df, training_error_ratesL), (test_attr_df, test_class_df, testing_error_ratesL)]\n",
    "\n",
    "for attrs, labels, error_ratesL in sets:\n",
    "\n",
    "    for k in k_vals:\n",
    "        \n",
    "        # specify the paramters of our model\n",
    "        model = knn(n_neighbors=k, metric = \"euclidean\")\n",
    "        # Alternatively, could set the power paramter p = 2 to get the Euclidean metric\n",
    "        \n",
    "        # We train/fit our model with the training set data\n",
    "        model.fit(train_attr_df, train_class_df)\n",
    "        \n",
    "        errors = 0\n",
    "        # using count to track the indices during the loop and compare the predicted class with the true ones\n",
    "        count = 0\n",
    "        # the predict() method classifies the unlabeled data based on the previous training of the model\n",
    "        for label in model.predict(attrs):\n",
    "            if label != labels[count]:\n",
    "                errors += 1\n",
    "            count += 1\n",
    "\n",
    "        # error rate is the number of misclassified points divided by number of all test data\n",
    "        error_rate = errors/len(model.predict(attrs))\n",
    "\n",
    "        error_ratesL.append(error_rate)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Line graph of the training and testing error rate in terms of k for k ∈ {208, 205, . . . , 7, 4, 1, } (in reverse order)\n",
    "plt.plot(k_vals, testing_error_ratesL)\n",
    "plt.plot(k_vals, training_error_ratesL)\n",
    "plt.xlabel(\"K\")\n",
    "plt.ylabel(\"Error Rate\")\n",
    "plt.legend([\"Testing Error\", \"Training Error\"])\n",
    "plt.grid(True)\n",
    "# By inverting the standard positions of the xlim() the graph is in reverse x order\n",
    "# add +5 simply for visual reasons so the graph doesn't start and stop exactly with the plot line\n",
    "plt.xlim(max(k_vals)+5, min(k_vals)-5)\n",
    "plt.show()\n",
    "\n",
    "# Not asked for, but helpful for interpretation\n",
    "df = pd.DataFrame()\n",
    "df[\"k\"] = k_vals\n",
    "df[\"Training Error Rate\"] = training_error_ratesL\n",
    "df[\"Testing Error Rate\"] = testing_error_ratesL\n",
    "display(df)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# initializing best_k such that the while loop starts\n",
    "best_k = 1\n",
    "# Was told that 1 cannot be a valid k* since its using itself as a neighbor; need to exclude the possibility k* = 1\n",
    "while best_k == 1:\n",
    "    best_testing_error_rate = min(testing_error_ratesL)\n",
    "    # using [::-1] since k_vals is sorted hgihest to lowest\n",
    "    best_k = k_vals[::-1][testing_error_ratesL[::-1].index(best_testing_error_rate)]\n",
    "    if 1 in k_vals: k_vals.remove(1)\n",
    "# need to return the 1, since k_vals is often reused without being redefined\n",
    "k_vals.insert(len(k_vals), 1)\n",
    "\n",
    "print(\"For KNN Classification with Euclidean metric:\")\n",
    "print(\"k* =\", best_k)\n",
    "print(\"Resulting in best testing error rate of\", best_testing_error_rate)\n",
    "# classmate got 5; check with others\n",
    "\n",
    "# Getting the best classifier and its results (at k*) -- to calculate measures accuracy\n",
    "best_model = knn(n_neighbors=best_k, metric = \"euclidean\")\n",
    "best_model.fit(train_attr_df, train_class_df)\n",
    "best_pred = best_model.predict(test_attr_df)\n",
    "\n",
    "# https://scikit-learn.org/stable/modules/generated/sklearn.metrics.confusion_matrix.html\n",
    "matrix = confusion_matrix(test_class_df, best_pred)\n",
    "\n",
    "# https://seaborn.pydata.org/generated/seaborn.heatmap.html\n",
    "sns.heatmap(matrix, annot=True)\n",
    "plt.title(\"Confusion Matrix\")\n",
    "plt.xlabel(\"Predicted Label\")\n",
    "plt.ylabel(\"True Label\")\n",
    "plt.show()\n",
    "\n",
    "matrix_flat = matrix.flatten()\n",
    "tn = matrix_flat[0]\n",
    "fp = matrix_flat[1]\n",
    "fn = matrix_flat[2]\n",
    "tp = matrix_flat[3]\n",
    "print(\"TN =\", tn, \"\\nFP =\", fp, \"\\nFN =\", fn, \"\\nTP =\", tp)\n",
    "\n",
    "tpr = tp/(tp+fn)\n",
    "tnr = tn/(tn+fp)\n",
    "prec = tp/(tp+fp)\n",
    "f1 = tp/(tp+0.5*(fp+fn))\n",
    "print(\"TPR =\", tpr)\n",
    "print(\"TNR =\", tnr)\n",
    "print(\"Precision =\", prec)\n",
    "print(\"F1-score =\", f1)\n",
    "\n",
    "# Also, there is a function that gives the percision and f1-score; uncomment lines below if see\n",
    "# from sklearn.metrics import classification_report\n",
    "# print()\n",
    "# report = classification_report(test_class_df, best_pred)\n",
    "# print(report)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "--------------------\n",
    "## (c).iii \n",
    "Classification using KNN on Vertebral Column Data Set\n",
    "\n",
    "iii. Since the computation time depends on the size of the training set, one may only use a subset of the training set. Plot the best test error rate, which is obtained by some value of k, against the size of training set, when the size of training set is N ∈ {10,20,30,...,210}. Note: for each N, select your training set by choosing the first ⌊N/3⌋ rows of Class 0 and the first N − ⌊N/3⌋ rows of Class 1 in the training set you created in 1(b)iii. Also, for each N, select the optimal k from a set starting from k = 1, increasing by 5. For example, if N = 200, the optimal k is selected from {1,6,11,...,196}. This plot is called a Learning Curve."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1.c.iii\n",
    "\n",
    "n_list = list(range(10, 211, 10))\n",
    "\n",
    "# display(test_set_df)\n",
    "\n",
    "best_ks_list = []\n",
    "best_testing_error_ratesL = []\n",
    "\n",
    "# looping through the list of n's to record the best k and test error rate based on training sample size\n",
    "for n in n_list:\n",
    "\n",
    "    train_set = [class0_df[:(n//3)], class1_df[:(n-n//3)]]\n",
    "    # ignore_index argument basically, resets the index for the new df\n",
    "    train_set_df = pd.concat(train_set, ignore_index=True)\n",
    "    \n",
    "    train_attr_df = train_set_df[col_names]\n",
    "    train_class_df = train_set_df[\"class\"]\n",
    "    \n",
    "    k_vals = list(range(1, n, 5))\n",
    "    \n",
    "    testing_error_ratesL = []\n",
    "\n",
    "    for k in k_vals:\n",
    "        \n",
    "        # We build our model per our k and metric parameter specifications\n",
    "        model = knn(n_neighbors=k, metric = \"euclidean\")\n",
    "        # We train the model\n",
    "        model.fit(train_attr_df, train_class_df)\n",
    "        \n",
    "        errors = 0\n",
    "        # using count to track the indices during the loop and compare the predicted class with the true ones\n",
    "        count = 0\n",
    "        # the predict() method classifies the unlabeled data based on the previous training of the model\n",
    "        for label in model.predict(test_attr_df):\n",
    "            if label != test_class_df[count]:\n",
    "                errors += 1\n",
    "            count += 1\n",
    "\n",
    "        # error rate is the number of misclassified points divided by number of all test data\n",
    "        testing_error_rate = errors/len(model.predict(test_attr_df))\n",
    "        testing_error_ratesL.append(testing_error_rate)\n",
    "    \n",
    "    # initializing best_k such that the while loop starts\n",
    "    best_k = 1\n",
    "    # Was told that 1 cannot be a valid k* since its using itself as a neighbor; need to exclude the possibility k* = 1\n",
    "    while best_k == 1:\n",
    "        # Even if there are multiple testing error rates of the same best size, since k_vals is sorted least to greatest we still get the optimal k by selecting the first applicable k\n",
    "        best_testing_error_rate = min(testing_error_ratesL)\n",
    "        best_k = k_vals[testing_error_ratesL.index(best_testing_error_rate)]\n",
    "        if 1 in k_vals: k_vals.remove(1)\n",
    "    # need to return the 1, since k_vals is often reused without being redefined\n",
    "    k_vals.insert(0, 1)\n",
    "    \n",
    "    best_testing_error_ratesL.append(best_testing_error_rate)\n",
    "    best_ks_list.append(best_k)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Line graph of the best test error rate against training set size (N) for N ∈ {10,20,30,...,210}\n",
    "# ie plot of the learning curve\n",
    "plt.plot(n_list, best_testing_error_ratesL)\n",
    "plt.xlabel(\"Size of Training Set (N)\")\n",
    "plt.ylabel(\"Best Test Error Rate\")\n",
    "plt.title(\"Learning Curve\")\n",
    "plt.grid(True)\n",
    "plt.show()\n",
    "\n",
    "# This displays a dataframe for the various data relevant to the Learning Curve\n",
    "# Not asked for, but helpful for interpretation\n",
    "ln_df = pd.DataFrame()\n",
    "ln_df[\"N Size\"] = n_list\n",
    "ln_df[\"Best Test Error Rate\"] = best_testing_error_ratesL\n",
    "ln_df[\"Optimal k\"] = best_ks_list\n",
    "display(ln_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "-------------------\n",
    "## (d).i.A.\n",
    "Replace the Euclidean metric with the following metrics5 and test them. Sum- marize the test errors (i.e., when k = k∗) in a table. Use all of your training data and select the best k when {1,6,11,...,196}.\n",
    "\n",
    "i. Minkowski Distance:\n",
    "\n",
    "A. which becomes Manhattan Distance with p = 1."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# The code is fairly similar to (c), could optimize the code by creating a function for it\n",
    "\n",
    "# can make more efficient by changing the name of train_set_df in c.iii, so I don't have to redefine it\n",
    "train_set = [class0_df[:70], class1_df[:140]]\n",
    "train_set_df = pd.concat(train_set, ignore_index=True)\n",
    "\n",
    "k_vals = list(range(1, 200, 5))\n",
    "\n",
    "testing_errorsL = []\n",
    "testing_error_ratesL = []\n",
    "\n",
    "\n",
    "for k in k_vals:\n",
    "\n",
    "    # Here is the main difference for (d).i.A; we set the metric as \"manhattan\"\n",
    "    # Alternatively can use the parameter p=1 to represent the Manhattan distance \n",
    "    # We build our model per our k and metric parameter specifications        \n",
    "    model = knn(n_neighbors=k, metric = \"manhattan\")\n",
    "    # We train the model\n",
    "    model.fit(train_attr_df, train_class_df)\n",
    "\n",
    "    errors = 0\n",
    "    count = 0\n",
    "    # the predict() method classifies the unlabeled data based on the previous training of the model\n",
    "    for label in model.predict(test_attr_df):\n",
    "        if label != test_class_df[count]:\n",
    "            errors += 1\n",
    "        count += 1\n",
    "    \n",
    "    testing_errorsL.append(errors)\n",
    "    testing_error_rate = errors/len(model.predict(test_attr_df))\n",
    "    testing_error_ratesL.append(testing_error_rate)\n",
    "\n",
    "# initializing best_k such that the while loop starts\n",
    "best_k = 1\n",
    "# Was told that 1 cannot be a valid k* since its using itself as a neighbor; need to exclude the possibility k* = 1\n",
    "while best_k == 1:\n",
    "    # Even if there are multiple testing error rates of the same best size, since k_vals is sorted least to greatest we still get the optimal k by selecting the first applicable k\n",
    "    best_testing_error_rate = min(testing_error_ratesL)\n",
    "    best_k = k_vals[testing_error_ratesL.index(best_testing_error_rate)]\n",
    "    if 1 in k_vals: k_vals.remove(1)\n",
    "# need to return the 1, since k_vals is often reused without being redefined\n",
    "k_vals.insert(0, 1)\n",
    "\n",
    "print(\"For KNN Classification with Manhattan Distance:\")\n",
    "print(\"k* =\", best_k)\n",
    "print(\"Resulting in best testing error rate of\", best_testing_error_rate)\n",
    "\n",
    "df = pd.DataFrame()\n",
    "df[\"k\"] = k_vals\n",
    "df[\"Testing Error\"] = testing_errorsL\n",
    "df[\"Testing Error Rate\"] = testing_error_ratesL\n",
    "display(df)\n",
    "\n",
    "# Not asked for, but helpful for interpretation\n",
    "# Line graph of the testing error rate in terms of k for k ∈ {1,6,11,...,196} with Manhattan Distance\n",
    "plt.plot(k_vals, testing_error_ratesL)\n",
    "plt.xlabel(\"k\")\n",
    "plt.ylabel(\"Error Rate\")\n",
    "plt.title(\"KNN Classification with Manhattan Distance\")\n",
    "plt.grid(True)\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "-------------------\n",
    "## (d).i.B. \n",
    "Replace the Euclidean metric with the following metrics5 and test them. Sum- marize the test errors (i.e., when k = k∗) in a table. Use all of your training data and select the best k when {1,6,11,...,196}.\n",
    "\n",
    "i. Minkowski Distance:\n",
    "\n",
    "B. with log10(p) ∈ {0.1,0.2,0.3,...,1}. In this case, use the k∗ you found for the Manhattan distance in 1(d)iA. What is the best log10(p)?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "testing_errorsL = []\n",
    "testing_error_ratesL = []\n",
    "\n",
    "\n",
    "log10p = list(np.linspace(0.1, 1, 10))\n",
    "log10p = [round(i, 2) for i in log10p]\n",
    "# convert the given log10(p) ∈ {0.1,0.2,0.3,...,1} set to one with the p parameter isolated\n",
    "p_list = [round(10**i, 4) for i in log10p]\n",
    "\n",
    "for p in p_list:\n",
    "    \n",
    "    # We build our model per our k and metric parameter specifications        \n",
    "    model = knn(n_neighbors=best_k, metric = \"minkowski\", p=p)\n",
    "    # We train the model\n",
    "    model.fit(train_attr_df, train_class_df)\n",
    "\n",
    "    errors = 0\n",
    "    # using count to track the indices during the loop and compare the predicted class with the true ones\n",
    "    count = 0\n",
    "    # the predict() method classifies the unlabeled data based on the previous training of the model\n",
    "    for label in model.predict(test_attr_df):\n",
    "        if label != test_class_df[count]:\n",
    "            errors += 1\n",
    "        count += 1\n",
    "    \n",
    "    testing_errorsL.append(errors)\n",
    "    testing_error_rate = errors/len(model.predict(test_attr_df))\n",
    "    testing_error_ratesL.append(testing_error_rate)\n",
    "\n",
    "best_testing_error_rate = min(testing_error_ratesL)\n",
    "best_p = p_list[testing_error_ratesL.index(best_testing_error_rate)]\n",
    "best_log10p = np.log10(best_p)\n",
    "\n",
    "# print(\"log10(p) =\", round(best_log10p, 1))\n",
    "print(\"For KNN Classification with Minkowski Distance (and k* =\", str(best_k) + \"):\")\n",
    "print(\"The best log10(p) =\", str(round(best_log10p, 1)) + \", resulting in the best testing error rate of\", best_testing_error_rate)\n",
    "\n",
    "df = pd.DataFrame()\n",
    "df[\"k\"] = [best_k]*len(p_list)\n",
    "df[\"log10(p)\"] = log10p\n",
    "df[\"p\"] = p_list\n",
    "df[\"Testing Error Rate\"] = testing_error_ratesL\n",
    "display(df)\n",
    "\n",
    "\n",
    "# Not asked for, but helpful for interpretation\n",
    "# Line graph of the testing error rate plotted against log10(p) for log10(p) ∈ {0.1,0.2,0.3,...,1} with Minkowski Distance\n",
    "plt.plot(log10p, testing_error_ratesL)\n",
    "plt.xlabel(\"log10(p)\")\n",
    "plt.ylabel(\"Testing Error Rate\")\n",
    "plt.title(\"KNN Classification at k=1 with Minkowski Distance and Varying p\")\n",
    "plt.grid(True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---------------\n",
    "## (d).i.C. \n",
    "Replace the Euclidean metric with the following metrics and test them. Sum- marize the test errors (i.e., when k = k∗) in a table. Use all of your training data and select the best k when {1,6,11,...,196}.\n",
    "\n",
    "i. Minkowski Distance:\n",
    "\n",
    "C. which becomes Chebyshev Distance with p → ∞"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# almost identical to A; could make more efficient using a function\n",
    "\n",
    "testing_errorsL = []\n",
    "testing_error_ratesL = []\n",
    "\n",
    "\n",
    "for k in k_vals:\n",
    "    \n",
    "    # We build our model per our k and metric parameter specifications        \n",
    "    model = knn(n_neighbors=k, metric = \"chebyshev\")\n",
    "    # We train the model\n",
    "    model.fit(train_attr_df, train_class_df)\n",
    "\n",
    "    errors = 0\n",
    "    # using count to track the indices during the loop and compare the predicted class with the true ones\n",
    "    count = 0\n",
    "    # the predict() method classifies the unlabeled data based on the previous training of the model\n",
    "    for label in model.predict(test_attr_df):\n",
    "        if label != test_class_df[count]:\n",
    "            errors += 1\n",
    "        count += 1\n",
    "    \n",
    "    testing_errorsL.append(errors)\n",
    "    testing_error_rate = errors/len(model.predict(test_attr_df))\n",
    "    testing_error_ratesL.append(testing_error_rate)\n",
    "\n",
    "# initializing best_k such that the while loop starts\n",
    "best_k = 1\n",
    "# Was told that 1 cannot be a valid k* since its using itself as a neighbor; need to exclude the possibility k* = 1\n",
    "while best_k == 1:\n",
    "    # Even if there are multiple testing error rates of the same best size, since k_vals is sorted least to greatest we still get the optimal k by selecting the first applicable k\n",
    "    best_testing_error_rate = min(testing_error_ratesL)\n",
    "    best_k = k_vals[testing_error_ratesL.index(best_testing_error_rate)]\n",
    "    if 1 in k_vals: k_vals.remove(1)\n",
    "# need to return the 1, since k_vals is often reused without being redefined\n",
    "k_vals.insert(0, 1)\n",
    "\n",
    "print(\"For KNN Classification with Chebyshev Distance:\")\n",
    "print(\"k* =\", best_k)\n",
    "print(\"Resulting in best testing error rate of\", best_testing_error_rate)\n",
    "\n",
    "df = pd.DataFrame()\n",
    "df[\"k\"] = k_vals\n",
    "df[\"Testing Error\"] = testing_errorsL\n",
    "df[\"Testing Error Rate\"] = testing_error_ratesL\n",
    "display(df)\n",
    "\n",
    "# Not asked for, but helpful for interpretation\n",
    "# Line graph of the testing error rate in terms of k for k ∈ {1,6,11,...,196} with Chebyshev Distance\n",
    "plt.plot(k_vals, testing_error_ratesL)\n",
    "plt.xlabel(\"k\")\n",
    "plt.ylabel(\"Testing Error Rate\")\n",
    "plt.title(\"KNN Classification with Chebyshev Distance\")\n",
    "plt.grid(True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "-------------\n",
    "## (d).ii.\n",
    "Replace the Euclidean metric with the following metrics5 and test them. Sum- marize the test errors (i.e., when k = k∗) in a table. Use all of your training data and select the best k when {1,6,11,...,196}.\n",
    "\n",
    "ii. Mahalanobis Distance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# code to ignore all future warnings\n",
    "simplefilter(action=\"ignore\", category=FutureWarning)\n",
    "# action = \"default\" to return to normal\n",
    "# Or else, the following code is printing along with the output for every k interation, thus clutering the output area\n",
    "# /Applications/anaconda3/lib/python3.8/site-packages/sklearn/metrics/pairwise.py:1460: FutureWarning: from version 0.25, pairwise_distances for metric='mahalanobis' will require VI to be specified if Y is passed. warnings.warn(\"from version 0.25, pairwise_distances for \"\n",
    "\n",
    "testing_errorsL = []\n",
    "testing_error_ratesL = []\n",
    "\n",
    "\n",
    "for k in k_vals:\n",
    "    \n",
    "    # We need the covariance matrix of the test set's features as a paramter for the Mahalanobis metric \n",
    "    cov_mat = np.cov(train_attr_df, rowvar = False)\n",
    "    # if rowvar = True, the rows are treated as the variables\n",
    "    \n",
    "    # We build our model per our k and metric parameter specifications\n",
    "    model = knn(n_neighbors=k, metric = \"mahalanobis\", metric_params={'V': cov_mat})\n",
    "    # We train the model\n",
    "    model.fit(train_attr_df, train_class_df)\n",
    "\n",
    "    errors = 0\n",
    "    # using count to track the indices during the loop and compare the predicted class with the true ones\n",
    "    count = 0\n",
    "    # the predict() method classifies the unlabeled data based on the previous training of the model\n",
    "    for label in model.predict(test_attr_df):\n",
    "        if label != test_class_df[count]:\n",
    "            errors += 1\n",
    "        count += 1\n",
    "    \n",
    "    testing_errorsL.append(errors)\n",
    "    testing_error_rate = errors/len(model.predict(test_attr_df))\n",
    "    testing_error_ratesL.append(testing_error_rate)\n",
    "\n",
    "# initializing best_k such that the while loop starts\n",
    "best_k = 1\n",
    "# Was told that 1 cannot be a valid k* since its using itself as a neighbor; need to exclude the possibility k* = 1\n",
    "while best_k == 1:\n",
    "    # Even if there are multiple testing error rates of the same best size, since k_vals is sorted least to greatest we still get the optimal k by selecting the first applicable k\n",
    "    best_testing_error_rate = min(testing_error_ratesL)\n",
    "    best_k = k_vals[testing_error_ratesL.index(best_testing_error_rate)]\n",
    "    if 1 in k_vals: k_vals.remove(1)\n",
    "# need to return the 1, since k_vals is often reused without being redefined\n",
    "k_vals.insert(0, 1)\n",
    "\n",
    "print(\"For KNN Classification with Mahalanobis Distance:\")\n",
    "print(\"k* =\", best_k)\n",
    "print(\"Resulting in best testing error rate of\", best_testing_error_rate)\n",
    "\n",
    "df = pd.DataFrame()\n",
    "df[\"k\"] = k_vals\n",
    "df[\"Testing Error\"] = testing_errorsL\n",
    "df[\"Testing Error Rate\"] = testing_error_ratesL\n",
    "display(df)\n",
    "\n",
    "# Not asked for, but helpful for interpretation\n",
    "# Line graph of the testing error rate in terms of k for k ∈ {1,6,11,...,196} with Mahalanobis Distance\n",
    "plt.plot(k_vals, testing_error_ratesL)\n",
    "plt.xlabel(\"k\")\n",
    "plt.ylabel(\"Testing Error Rate\")\n",
    "plt.title(\"KNN Classification with Mahalanobis Distance\")\n",
    "plt.grid(True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Summary Table of (d) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "index = [\"k*\", \"Best Test Error Rate\"]\n",
    "manhattan = [6, 0.11]\n",
    "minkowski = [6, 0.06]\n",
    "chebyshev = [16, 0.08]\n",
    "mahalanobis = [6, 0.15]\n",
    "\n",
    "df = pd.DataFrame()\n",
    "df[\"\"] = index\n",
    "df[\"Manhattan\"] = manhattan\n",
    "df[\"Minkowski\"] = minkowski\n",
    "df[\"Chebyshev\"] = chebyshev\n",
    "df[\"Mahalanobis\"] = mahalanobis\n",
    "display(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "------------------\n",
    "## (e)\n",
    "The majority polling decision can be replaced by weighted decision, in which the weight of each point in voting is inversely proportional to its distance from the query/test data point. In this case, closer neighbors of a query point will have a greater influence than neighbors which are further away. Use weighted voting with Euclidean, Manhattan, and Chebyshev distances and report the best test errors when k ∈ {1,6,11,16,...,196}."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# We basically rerun the classification model from the previous question, using \"weighted decision\"\n",
    "# A lot of the code is the same, and can likely be optimized by creating a function at the start\n",
    "\n",
    "dist_typesL = [\"Euclidean\", \"Manhattan\", \"Chebyshev\"]\n",
    "\n",
    "for dist_type in dist_typesL:\n",
    "\n",
    "    testing_errorsL = []\n",
    "    testing_error_ratesL = []\n",
    "    \n",
    "    for k in k_vals:\n",
    "\n",
    "        # Setting the parameter weight=\"distance\" makes the classifier into a wieghted decision one\n",
    "        # We build our model per our k and metric parameter specifications        \n",
    "        model = knn(n_neighbors=k, weights=\"distance\", metric = dist_type.lower())\n",
    "        # We train the model\n",
    "        model.fit(train_attr_df, train_class_df)\n",
    "\n",
    "        errors = 0\n",
    "        # using count to track the indices during the loop and compare the predicted class with the true ones\n",
    "        count = 0\n",
    "        # the predict() method classifies the unlabeled data based on the previous training of the model\n",
    "        for label in model.predict(test_attr_df):\n",
    "            if label != test_class_df[count]:\n",
    "                errors += 1\n",
    "            count += 1\n",
    "\n",
    "        testing_errorsL.append(errors)\n",
    "        testing_error_rate = errors/len(model.predict(test_attr_df))\n",
    "        testing_error_ratesL.append(testing_error_rate)\n",
    "\n",
    "    # initializing best_k such that the while loop starts\n",
    "    best_k = 1\n",
    "    # Was told that 1 cannot be a valid k* since its using itself as a neighbor; need to exclude the possibility k* = 1\n",
    "    while best_k == 1:\n",
    "        # Even if there are multiple testing error rates of the same best size, since k_vals is sorted least to greatest we still get the optimal k by selecting the first applicable k\n",
    "        best_testing_error_rate = min(testing_error_ratesL)\n",
    "        best_k = k_vals[testing_error_ratesL.index(best_testing_error_rate)]\n",
    "        if 1 in k_vals: k_vals.remove(1)\n",
    "    # need to return the 1, since k_vals is often reused without being redefined\n",
    "    k_vals.insert(0, 1)\n",
    "    \n",
    "    print(\"\\nFor KNN Classification by weighted decision with\", dist_type, \"Distance:\")\n",
    "    print(\"k* =\", best_k)\n",
    "    print(\"Resulting in best testing error rate of\", best_testing_error_rate)\n",
    "\n",
    "    df = pd.DataFrame()\n",
    "    df[\"k\"] = k_vals\n",
    "    df[\"Testing Error\"] = testing_errorsL\n",
    "    df[\"Testing Error Rate\"] = testing_error_ratesL\n",
    "    display(df)\n",
    "\n",
    "    # Not asked for, but helpful for interpretation\n",
    "    # Line graph of the testing error rate in terms of k for k ∈ {1,6,11,...,196} based on weighted decision\n",
    "    plt.plot(k_vals, testing_error_ratesL)\n",
    "    plt.xlabel(\"k\")\n",
    "    plt.ylabel(\"Testing Error Rate\")\n",
    "    plt.title(\"KNN Classification with %s Distance\" %dist_type)\n",
    "    plt.grid(True)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Summary Table of (e) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "index = [\"k*\", \"Best Test Error Rate\"]\n",
    "euclidean = [6, 0.1]\n",
    "manhattan = [26, 0.1]\n",
    "chebyshev = [16, 0.11]\n",
    "\n",
    "df = pd.DataFrame()\n",
    "df[\"\"] = index\n",
    "df[\"Euclidean\"] = euclidean\n",
    "df[\"Manhattan\"] = manhattan\n",
    "df[\"Chebyshev\"] = chebyshev\n",
    "display(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---------------\n",
    "## (f)\n",
    "What is the lowest training error rate you achieved in this homework?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The lowest training error rate we achieved is 0.0 at 𝑘 = 1 -- in part (c) -- using the Eucidean metric. The KNN training error at k = 1 is based on classifying a sample from the training set by using only itself as its nearest neighbor. So obviously it would have 0 errors."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
